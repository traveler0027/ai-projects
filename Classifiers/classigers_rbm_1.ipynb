{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib is used to downlaod the utils frile from deeplearning.net\n",
    "\n",
    "import urllib.request\n",
    "with urllib.request.urlopen(\"http://deeplearning.net/tutorial/code/utils.py\") as url:\n",
    "    response = url.read()\n",
    "target = open('utils.py','w')\n",
    "target.write(response.decode('utf-8'))\n",
    "target.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from utils import tile_raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class that defines the behavious of the RBM\n",
    "class RBM(object):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        #defineing the hyperparameters\n",
    "        self._input_size = input_size\n",
    "        self._output_size = output_size\n",
    "        self.epochs = 5 #epoch is a training iteration\n",
    "        self.learning_rate = 1.0 #the step used in the gradiate descent\n",
    "        self.batchsize = 100 #size of how much data will be used for training per sub iteration\n",
    "        \n",
    "        #initializing weights and biases as matrices full of zeroes\n",
    "        self.w = np.zeros([input_size,output_size],np.float32)\n",
    "        self.hb = np.zeros([output_size],np.float32) #creates ad ninitializes hidden bias\n",
    "        self.vb = np.zeros([input_size],np.float32) #creates and initializes the visible bias\n",
    "        \n",
    "    #fits the results from the weighted visible layer plus the bias into a sigmoid curve\n",
    "    def prob_h_given_v(self,visible,w,hb):\n",
    "        #sigmoid\n",
    "        return tf.nn.sigmoid(tf.matmul(visible,w)+hb)\n",
    "    \n",
    "    #fits the results from the weighted hidden layer plus the bias into a sigmoid curve\n",
    "    def prob_v_given_h(self,hidden,w,vb):\n",
    "        #sigmoid\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w))+vb)\n",
    "    \n",
    "    #generates the sample probablility\n",
    "    def sample_prob(self,probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "    \n",
    "    #training method for the model\n",
    "    def train(self,x):\n",
    "        #create the placeholder for the parameters\n",
    "        _w = tf.placeholder(\"float\",[self._input_size,self._output_size])\n",
    "        _hb = tf.placeholder(\"float\",[self._output_size])\n",
    "        _vb = tf.placeholder(\"float\",[self._input_size])\n",
    "        \n",
    "        prv_w = np.zeros([self._input_size,self._output_size],np.float32) #initialize weights\n",
    "        prv_hb = np.zeros([self._output_size],np.float32)\n",
    "        prv_vb = np.zeros([self._input_size],np.float32)\n",
    "        \n",
    "        cur_w = np.zeros([self._input_size,self._output_size],np.float32)\n",
    "        cur_hb = np.zeros([self._output_size],np.float32)\n",
    "        cur_vb = np.zeros([self._input_size],np.float32)\n",
    "        v0 = tf.placeholder(\"float32\",[None,self._input_size])\n",
    "        \n",
    "        #initialize with smaple probabilities\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0,_w,_hb))\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0,_w,_vb))\n",
    "        h1 = self.prob_h_given_v(v1,_w,_hb)\n",
    "        \n",
    "        #create the gradiates\n",
    "        positive_grad = tf.matmul(tf.transpose(v0),h0)\n",
    "        negative_grad = tf.matmul(tf.transpose(v1),h1)\n",
    "        \n",
    "        #update learning rates for the layers\n",
    "        update_w = _w + self.learning_rate*(positive_grad - negative_grad)/tf.to_float(tf.shape(v0)[0])\n",
    "        update_vb = _vb + self.learning_rate*tf.reduce_mean(v0 - v1,0)\n",
    "        update_hb = _hb + self.learning_rate*tf.reduce_mean(h0 - h1,0)\n",
    "        \n",
    "        ##find error rate\n",
    "        err = tf.reduce_mean(tf.square(v0-v1))\n",
    "        \n",
    "        #training loop\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            #for each epoch\n",
    "            for epoch in range(self.epochs):\n",
    "                #for each step/batch\n",
    "                for start, end in zip(range(0,len(x),self.batchsize),range(self.batchsize,len(x),self.batchsize)):\n",
    "                    batch = x[start:end]\n",
    "                    cur_w = sess.run(update_w,feed_dict={v0:batch,_w:prv_w,_hb:prv_hb,_vb:prv_vb})\n",
    "                    cur_hb = sess.run(update_hb,feed_dict={v0:batch,_w:prv_w,_hb:prv_hb,_vb:prv_vb})\n",
    "                    cur_vb = sess.run(update_vb,feed_dict={v0:batch,_w:prv_w,_hb:prv_hb,_vb:prv_vb})\n",
    "                    prv_w=cur_w\n",
    "                    prv_hb=cur_hb\n",
    "                    prv_vb=cur_vb\n",
    "                error = sess.run(err,feed_dict={v0:x,_w:cur_w,_vb:cur_vb, _hb: cur_hb})\n",
    "                print('Epoch: %d'%epoch,'reconstruction error: %f'% error)\n",
    "            self.w = prv_w\n",
    "            self.hb = prv_hb\n",
    "            self.vb = prv_vb\n",
    "            \n",
    "    #create expected output for the DBN\n",
    "    def rbm_output(self,x):\n",
    "        input_x = tf.constant(x)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        out = tf.nn.sigmoid(tf.matmul(input_x,_w)+_hb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-a3cd7855580c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\jssrv\\_programs\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#read in the data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "#asign the trainign and test data\n",
    "trX,trY,teX,teY = mnist.train.images,mnist.train.labels,mnist.test.images,mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM:  0  784 -> 500\n",
      "RBM:  1  500 -> 200\n",
      "RBM:  2  200 -> 50\n"
     ]
    }
   ],
   "source": [
    "#create the deep belief network\n",
    "rbm_hidden_sizes = [500,200,50]\n",
    "\n",
    "inpx = trX\n",
    "rbm_list = []\n",
    "#size of the inputs is the number of inputs in the training set\n",
    "input_size = inpx.shape[1]\n",
    "\n",
    "for i,size in enumerate(rbm_hidden_sizes):\n",
    "    print('RBM: ',i,'',input_size,'->',size)\n",
    "    rbm_list.append(RBM(input_size,size))\n",
    "    input_size = size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New RBM:\n",
      "Epoch: 0 reconstruction error: 0.060405\n",
      "Epoch: 1 reconstruction error: 0.052860\n",
      "Epoch: 2 reconstruction error: 0.048933\n",
      "Epoch: 3 reconstruction error: 0.046987\n",
      "Epoch: 4 reconstruction error: 0.046126\n",
      "New RBM:\n",
      "Epoch: 0 reconstruction error: 0.037183\n",
      "Epoch: 1 reconstruction error: 0.032205\n",
      "Epoch: 2 reconstruction error: 0.030102\n",
      "Epoch: 3 reconstruction error: 0.028666\n",
      "Epoch: 4 reconstruction error: 0.028206\n",
      "New RBM:\n",
      "Epoch: 0 reconstruction error: 0.052309\n",
      "Epoch: 1 reconstruction error: 0.048687\n",
      "Epoch: 2 reconstruction error: 0.048108\n",
      "Epoch: 3 reconstruction error: 0.047539\n",
      "Epoch: 4 reconstruction error: 0.047226\n"
     ]
    }
   ],
   "source": [
    "#train the BRM\n",
    "for rbm in rbm_list:\n",
    "    print('New RBM:')\n",
    "    rbm.train(inpx)\n",
    "    inpx = rbm.rbm_output(inpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    \n",
    "    def __init__(self, sizes, X, Y):\n",
    "        #Initialize hyperparameters\n",
    "        self._sizes = sizes\n",
    "        self._X = X\n",
    "        self._Y = Y\n",
    "        self.w_list = []\n",
    "        self.b_list = []\n",
    "        self._learning_rate =  1.0\n",
    "        self._momentum = 0.0\n",
    "        self._epoches = 10\n",
    "        self._batchsize = 100\n",
    "        input_size = X.shape[1]\n",
    "        \n",
    "        #initialization loop\n",
    "        for size in self._sizes + [Y.shape[1]]:\n",
    "            #Define upper limit for the uniform distribution range\n",
    "            max_range = 4 * math.sqrt(6. / (input_size + size))\n",
    "            \n",
    "            #Initialize weights through a random uniform distribution\n",
    "            self.w_list.append(\n",
    "                np.random.uniform( -max_range, max_range, [input_size, size]).astype(np.float32))\n",
    "            \n",
    "            #Initialize bias as zeroes\n",
    "            self.b_list.append(np.zeros([size], np.float32))\n",
    "            input_size = size\n",
    "      \n",
    "    #load data from rbm\n",
    "    def load_from_rbms(self, dbn_sizes,rbm_list):\n",
    "        #Check if expected sizes are correct\n",
    "        assert len(dbn_sizes) == len(self._sizes)\n",
    "        \n",
    "        for i in range(len(self._sizes)):\n",
    "            #Check if for each RBN the expected sizes are correct\n",
    "            assert dbn_sizes[i] == self._sizes[i]\n",
    "        \n",
    "        #If everything is correct, bring over the weights and biases\n",
    "        for i in range(len(self._sizes)):\n",
    "            self.w_list[i] = rbm_list[i].w\n",
    "            self.b_list[i] = rbm_list[i].hb\n",
    "\n",
    "    #Training method\n",
    "    def train(self):\n",
    "        #Create placeholders for input, weights, biases, output\n",
    "        _a = [None] * (len(self._sizes) + 2)\n",
    "        _w = [None] * (len(self._sizes) + 1)\n",
    "        _b = [None] * (len(self._sizes) + 1)\n",
    "        _a[0] = tf.placeholder(\"float\", [None, self._X.shape[1]])\n",
    "        y = tf.placeholder(\"float\", [None, self._Y.shape[1]])\n",
    "        \n",
    "        #Define variables and activation functoin\n",
    "        for i in range(len(self._sizes) + 1):\n",
    "            _w[i] = tf.Variable(self.w_list[i])\n",
    "            _b[i] = tf.Variable(self.b_list[i])\n",
    "        for i in range(1, len(self._sizes) + 2):\n",
    "            _a[i] = tf.nn.sigmoid(tf.matmul(_a[i - 1], _w[i - 1]) + _b[i - 1])\n",
    "        \n",
    "        #Define the cost function\n",
    "        cost = tf.reduce_mean(tf.square(_a[-1] - y))\n",
    "        \n",
    "        #Define the training operation (Momentum Optimizer minimizing the Cost function)\n",
    "        train_op = tf.train.MomentumOptimizer(self._learning_rate, self._momentum).minimize(cost)\n",
    "        \n",
    "        #Prediction operation\n",
    "        predict_op = tf.argmax(_a[-1], 1)\n",
    "        \n",
    "        #Training Loop\n",
    "        with tf.Session() as sess:\n",
    "            #Initialize Variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            #For each epoch\n",
    "            for i in range(self._epoches):\n",
    "                \n",
    "                #For each step\n",
    "                for start, end in zip(range(0, len(self._X), self._batchsize), range(self._batchsize, len(self._X), self._batchsize)):\n",
    "                    \n",
    "                    #Run the training operation on the input data\n",
    "                    sess.run(train_op, feed_dict={ _a[0]: self._X[start:end], y: self._Y[start:end]})\n",
    "                \n",
    "                for j in range(len(self._sizes) + 1):\n",
    "                    #Retrieve weights and biases\n",
    "                    self.w_list[j] = sess.run(_w[j])\n",
    "                    self.b_list[j] = sess.run(_b[j])\n",
    "                \n",
    "                print (\"Accuracy rating for epoch \" + str(i) + \": \" + str(np.mean(np.argmax(self._Y, axis=1) == sess.run(predict_op, feed_dict={_a[0]: self._X, y: self._Y}))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rating for epoch 0: 0.4767272727272727\n",
      "Accuracy rating for epoch 1: 0.6291818181818182\n",
      "Accuracy rating for epoch 2: 0.7335272727272727\n",
      "Accuracy rating for epoch 3: 0.7728909090909091\n",
      "Accuracy rating for epoch 4: 0.7914181818181818\n",
      "Accuracy rating for epoch 5: 0.8032\n",
      "Accuracy rating for epoch 6: 0.8154727272727272\n",
      "Accuracy rating for epoch 7: 0.8438\n",
      "Accuracy rating for epoch 8: 0.8756545454545455\n",
      "Accuracy rating for epoch 9: 0.8982909090909091\n"
     ]
    }
   ],
   "source": [
    "nNet = NN(rbm_hidden_sizes,trX,trY)\n",
    "nNet.load_from_rbms(rbm_hidden_sizes,rbm_list)\n",
    "nNet.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
